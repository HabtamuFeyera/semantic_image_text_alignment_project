{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Style Transfer\n",
    "# Implementation using a pre-trained Neural Style Transfer model\n",
    "# Example: Fast Neural Style Transfer with PyTorch\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vgg19\n",
    "from torchvision.utils import save_image\n",
    "from transformer_net import TransformerNet  # Custom transformer network\n",
    "from PIL import Image\n",
    "\n",
    "# Load pre-trained VGG19 model for feature extraction\n",
    "vgg = vgg19(pretrained=True).features.eval()\n",
    "\n",
    "# Load pre-trained style transfer model\n",
    "model = TransformerNet()\n",
    "model.load_state_dict(torch.load('pretrained_model.pth'))  # Load pre-trained model weights\n",
    "model.eval()\n",
    "\n",
    "# Preprocessing and postprocessing transforms\n",
    "preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Lambda(lambda x: x.mul(255))])\n",
    "postprocess = transforms.Compose([transforms.Lambda(lambda x: x.mul(1./255)),\n",
    "                                  transforms.ToPILImage()])\n",
    "\n",
    "# Load content image and style image\n",
    "content_img = Image.open('content.jpg')\n",
    "style_img = Image.open('style.jpg')\n",
    "\n",
    "# Apply style transfer\n",
    "content_tensor = preprocess(content_img).unsqueeze(0)\n",
    "style_tensor = preprocess(style_img).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    output = model(content_tensor, style_tensor)\n",
    "output_img = postprocess(output.squeeze(0))\n",
    "\n",
    "# Save or display the stylized image\n",
    "output_img.save('stylized_image.jpg')\n",
    "output_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Image Super-Resolution\n",
    "# Implementation using SRGAN (Super-Resolution Generative Adversarial Network)\n",
    "# Example: SRGAN implementation with PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from PIL import Image\n",
    "from models import Generator\n",
    "\n",
    "# Load pre-trained SRGAN generator model\n",
    "generator = Generator(upscale_factor=4)\n",
    "generator.load_state_dict(torch.load('srgan_generator.pth'))  # Load pre-trained generator weights\n",
    "generator.eval()\n",
    "\n",
    "# Define device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load low-resolution image\n",
    "lr_image = Image.open('low_resolution_image.jpg')\n",
    "\n",
    "# Transform low-resolution image to tensor\n",
    "lr_tensor = ToTensor()(lr_image).unsqueeze(0).to(device)\n",
    "\n",
    "# Generate high-resolution image\n",
    "with torch.no_grad():\n",
    "    sr_tensor = generator(lr_tensor)\n",
    "\n",
    "# Convert high-resolution tensor to PIL image\n",
    "sr_image = ToPILImage()(sr_tensor.squeeze(0).cpu())\n",
    "\n",
    "# Save or display the super-resolved image\n",
    "sr_image.save('super_resolved_image.jpg')\n",
    "sr_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Text Augmentation\n",
    "# Example: Synonym Replacement using NLTK\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def synonym_replacement(text, num_replacements=1):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    augmented_texts = []\n",
    "\n",
    "    for i in range(num_replacements):\n",
    "        for j, token in enumerate(tokens):\n",
    "            synsets = wordnet.synsets(token)\n",
    "            if synsets:\n",
    "                synonym = synsets[0].lemmas()[0].name()  # Get the first synonym\n",
    "                tokens[j] = synonym\n",
    "                break  # Replace only the first occurrence of a word\n",
    "        augmented_texts.append(' '.join(tokens))\n",
    "\n",
    "    return augmented_texts\n",
    "\n",
    "# Example usage\n",
    "original_text = \"This is a sample text for synonym replacement.\"\n",
    "augmented_texts = synonym_replacement(original_text, num_replacements=3)\n",
    "print(\"Original Text:\", original_text)\n",
    "print(\"Augmented Texts:\", augmented_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Font and Visual Properties\n",
    "# Implementation using Pillow (PIL)\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Open an image\n",
    "image = Image.open('background_image.jpg')\n",
    "\n",
    "# Initialize ImageDraw object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define font parameters\n",
    "font_path = 'arial.ttf'  # Path to font file\n",
    "font_size = 24\n",
    "font_color = (255, 255, 255)  # RGB color code\n",
    "\n",
    "# Load font\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "# Add text to image\n",
    "text = \"Sample Text\"\n",
    "text_width, text_height = draw.textsize(text, font=font)\n",
    "text_position = ((image.width - text_width) // 2, (image.height - text_height) // 2)\n",
    "draw.text(text_position, text, font=font, fill=font_color)\n",
    "\n",
    "# Save or display the image with text\n",
    "image.save('image_with_text.jpg')\n",
    "image.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
